<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Generative Adversarial Networks for Image Super-Resolution | David Pérez Carrasco </title> <meta name="author" content="David Pérez Carrasco"> <meta name="description" content="GAN-based Image Super-Resolution for enhanced detail recovery, achieving 4x upscaling of image resolution while preserving fine details."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://davidperezcarrasco.github.io/projects/3_project/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">David</span> Pérez Carrasco </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="text-align: justify;">Generative Adversarial Networks for Image Super-Resolution</h1> <p class="post-description" style="text-align: justify;">GAN-based Image Super-Resolution for enhanced detail recovery, achieving 4x upscaling of image resolution while preserving fine details.</p> </header> <article class="text-justify"> <p>This project delves into the realm of Image Super-Resolution (SR), a technique for generating high-resolution (HR) images from their low-resolution (LR) counterparts. This capability is particularly valuable when dealing with blurred or pixelated images, enabling the recovery of lost details and creation of visually superior versions. Our approach leverages the power of Generative Adversarial Networks (GANs), specifically the architecture proposed by <a href="https://arxiv.org/pdf/1609.04802.pdf" rel="external nofollow noopener" target="_blank">Super Resolution Generative Adversarial Networks (SRGAN)</a>.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-architecture-480.webp 480w,/assets/img/srgan-architecture-800.webp 800w,/assets/img/srgan-architecture-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="SRGAN Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> SRGAN Architecture </div> <p>For training and evaluation, we utilize the <a href="https://data.vision.ee.ethz.ch/cvl/DIV2K/" rel="external nofollow noopener" target="_blank">DIV2K dataset</a>, containing a rich collection of high-quality images. To prepare the data, we apply various transformations that augment the training set and enhance modelgeneralizability. Our network is designed to achieve a 4x upscaling factor, effectively quadrupling the resolution of the input LR image.</p> <h3 id="network-architecture-and-training-details">Network Architecture and Training Details</h3> <p><a href="https://github.com/davidperezcarrasco/SRGAN-for-Image-Super-Resolution" rel="external nofollow noopener" target="_blank">Our model</a> builds upon the core SRGAN architecture, which consists of a Generator and a Discriminator network. The Generator network employs a series of convolutional layers with Parametric ReLU activations, followed by five residual blocks with Batch Normalization. These residual blocks facilitate deeper network architectures and enhance gradient propagation. Subsequently, upscaling blocks with sub-pixel convolutions are utilized to achieve the desired 4x resolution increase. The Discriminator network, responsible for distinguishing between real HR images and the Generator’s outputs, leverages strided convolutions and fully-connected layers for image classification.</p> <p>To further improve the model’s performance, we leverage the principles of <a href="https://arxiv.org/pdf/1608.06993.pdf" rel="external nofollow noopener" target="_blank">Densely Connected Networks (DCNs)</a>. DCNs promote information flow throughout the network by establishing connections between each layer’s output and all subsequent layers. This strategy fosters feature reuse and facilitates gradient propagation, potentially leading to superior performance. We implement this concept by employing Densely Connected Residual Blocks. These blocks ensure that each layer receives inputs from all preceding layers, allowing the network to learn a more comprehensive representation of the image features. Additionally, we replace element-wise summation with weighted concatenation. This enables the network to assign varying importance to different feature maps, potentially leading to more effective feature utilization and improved image reconstruction.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-densenet-480.webp 480w,/assets/img/srgan-densenet-800.webp 800w,/assets/img/srgan-densenet-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-densenet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Densely Connected Convolutional Network" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Densely Connected Convolutional Network </div> <p>Furthermore, to enhance the Discriminator’s ability to discern real from generated images, we leverage transfer learning by incorporating a pre-trained VGG19 network. This pre-trained network extracts high-level features from the input HR images, aiding the Discriminator in making more accurate classifications.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-vgg19-480.webp 480w,/assets/img/srgan-vgg19-800.webp 800w,/assets/img/srgan-vgg19-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-vgg19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="VGG-19 is used as Transfer Learning for the Discriminator" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> VGG-19 is used as Transfer Learning for the Discriminator </div> <p>The training process involves optimizing a combination of loss functions. The Content Loss, initially implemented as MSE loss, was ultimately replaced with VGG-based perceptual loss to incorporate higher-level feature information. We also employ the Wasserstein Loss function for the Discriminator, promoting stable training dynamics. Finally, a Perceptual Loss is calculated, combining the Content Loss with the Discriminator’s feedback to guide the Generator towards producing realistic and detailed HR images.</p> <h3 id="training-performance-and-evaluation">Training Performance and Evaluation</h3> <p>Hyperparameter tuning plays a crucial role in achieving optimal model performance. We experimented with various learning rates, both unique and specific to different network components. The number of training epochs was carefully considered, balancing computational cost with the potential for diminishing returns. Additionally, we explored strategies for regulating the adversarial training process, ensuring a balanced competition between the Generator and Discriminator. Batch size selection was guided by the usage of Batch Normalization or Instance Normalization within the network architecture.</p> <p><strong>Convergence Analysis</strong></p> <p>The SRGAN training exhibits successful convergence, with the generator loss steadily decreasing to below 0.01 after 50 epochs, indicating effective learning to produce high-resolution images. The discriminator loss consistently hovers around -1, which aligns with the expected behavior for Wasserstein GANs where the loss is bounded. While a negative loss might seem unusual, it signifies the discriminator’s difficulty in differentiating between the generated high-resolution images and the real data. This reinforces the effectiveness of the training process, as the goal is precisely to generate images that closely resemble real HR examples. Furthermore, the fluctuations observed in the discriminator loss during initial stages are common in GAN training, reflecting the optimization process. In conclusion, the loss patterns provide strong evidence that the SRGAN is functioning well and achieving its objective of generating high-quality, realistic HR images.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-discloss-480.webp 480w,/assets/img/srgan-discloss-800.webp 800w,/assets/img/srgan-discloss-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-discloss.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Discriminator Loss" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-genloss-480.webp 480w,/assets/img/srgan-genloss-800.webp 800w,/assets/img/srgan-genloss-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-genloss.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Generator Loss" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Discriminator and Generator Losses </div> <p>To evaluate the model’s effectiveness, we employed two standard image quality metrics: Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM). These metrics quantify the fidelity between the generated HR image and the ground truth HR image. Our final model, termed Weighted Dense ResNet (WDRN) with VGG SRGAN, achieved a PSNR of 29.23 and SSIM of 0.739 after 50 epochs of training.</p> <h3 id="results">Results</h3> <p>The following images showcase the performance of our SRGAN model. We present comparisons showcasing the original low-resolution (LR) images alongside the corresponding high-resolution (HR) images generated by the model.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/more_results-480.webp 480w,/assets/img/more_results-800.webp 800w,/assets/img/more_results-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/more_results.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="LR vs SR Image Comparison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Original Low Resolution Images compared with the Super Resolution Generated Images by our Model </div> <p>To further assess our model’s performance, we directly compare its generated images with those produced by the <a href="https://arxiv.org/pdf/1609.04802.pdf" rel="external nofollow noopener" target="_blank">baseline SRGAN architecture</a>. We will present three images side-by-side: the original low-resolution input, the HR image generated by the baseline SRGAN (which might exhibit some blur), and the HR image created by our model, which showcases superior quality and smoother details.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-lo2-480.webp 480w,/assets/img/srgan-lo2-800.webp 800w,/assets/img/srgan-lo2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-lo2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Original Low Resolution Image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-benchmark-blur2-480.webp 480w,/assets/img/srgan-benchmark-blur2-800.webp 800w,/assets/img/srgan-benchmark-blur2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-benchmark-blur2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Super Resolution Generated Image from Baseline SRGAN Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/srgan-sr-480.webp 480w,/assets/img/srgan-sr-800.webp 800w,/assets/img/srgan-sr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/srgan-sr" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Super Resolution Generated Image from our SRGAN Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> From left to right: Original Low-Resolution Input, Baseline SRGAN Output (potential blur), Our Model's Output (improved quality and smoothness) </div> <h3 id="references">References</h3> <p>Arjovsky, M., Chintala, S., &amp; Bottou, L. (2017, July). <a href="https://proceedings.mlr.press/v70/arjovsky17a.html" rel="external nofollow noopener" target="_blank">Wasserstein generative adversarial networks</a>. In International conference on machine learning (pp. 214-223). PMLR.</p> <p>Chen, X., Wang, X., Zhou, J., Qiao, Y., &amp; Dong, C. (2023). <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.html" rel="external nofollow noopener" target="_blank">Activating more pixels in image super-resolution transformer</a>. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 22367-22377).</p> <p>Huang, G., Liu, Z., Van Der Maaten, L., &amp; Weinberger, K. Q. (2017). <a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html" rel="external nofollow noopener" target="_blank">Densely connected convolutional networks</a>. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4700-4708).</p> <p>Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., … &amp; Shi, W. (2017). <a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Ledig_Photo-Realistic_Single_Image_CVPR_2017_paper.html" rel="external nofollow noopener" target="_blank">Photo-realistic single image super-resolution using a generative adversarial network</a>. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4681-4690).</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 David Pérez Carrasco. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>