<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sentiment Analysis and Contextual Retrieval with LLMs and Transformers | David Pérez Carrasco </title> <meta name="author" content="David Pérez Carrasco"> <meta name="description" content="Sentiment analysis and contextual retrieval leveraging BERT, Hugging Face transformers, Mistral LLMs and ASR."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://davidperezcarrasco.github.io/projects/nlp/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">David</span> Pérez Carrasco </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" style="text-align: justify;">Sentiment Analysis and Contextual Retrieval with LLMs and Transformers</h1> <p class="post-description" style="text-align: justify;">Sentiment analysis and contextual retrieval leveraging BERT, Hugging Face transformers, Mistral LLMs and ASR.</p> </header> <article class="text-justify"> <p><a href="https://github.com/davidperezcarrasco/Sentiment-Analysis-and-Contextual-Retrieval-with-LLMs-and-Transformers" rel="external nofollow noopener" target="_blank">This project</a> focuses on implementing a comprehensive Natural Language Processing (NLP) pipeline for sentiment analysis and contextual comment retrieval using state-of-the-art transformer models. The system accepts text or audio input, converts the audio to text, predicts sentiment labels with a fine-tuned BERT text classification model, retrieves similar comments using cosine similarity from Hugging Face encodings, and generates summaries using a Mistral Face large language model (LLM). The integration of these components showcases advanced NLP techniques, including sentiment analysis, contextual embeddings, and prompt engineering, within a seamless and interactive web interface.</p> <h2 id="sentiment-analysis-with-berts-fine-tuning">Sentiment Analysis with BERT’s Fine Tuning</h2> <p>The core of the sentiment analysis component is based on the BERT large uncased emotions model. Fine-tuning this model involved extensive parameter tuning to optimize the precision, recall, and F1 score. Various configurations of maximum sequence length, batch size, learning rate, and epochs were tested to identify the best performing setup. The following table summarizes the results of tuning different hyperparameters for the <a href="https://huggingface.co/google-bert/bert-large-uncased" rel="external nofollow noopener" target="_blank">BERT text classification model</a>. The evaluation metrics include precision, recall, and F1 score for each configuration:</p> <div class="row justify-content-sm-center"> <div class="col-sm-9"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nlp/table1-480.webp 480w,/assets/img/nlp/table1-800.webp 800w,/assets/img/nlp/table1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/nlp/table1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Hyperparameter Tuning for BERT Text Classification Model" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Hyperparameter Tuning for BERT Text Classification Model </div> <p>The optimal configuration, highlighted by a combination of high precision, recall, and F1 score, was used to fine-tune the BERT model, enhancing its performance for the sentiment analysis task. The optimal threshold for the classes labeling was between 0.2 and 0.3, as highlighted in the <a href="https://github.com/davidperezcarrasco/Sentiment-Analysis-and-Contextual-Retrieval-with-LLMs-and-Transformers/blob/main/NLP_Report.pdf" rel="external nofollow noopener" target="_blank">report</a>.</p> <h2 id="retrieval-augmented-generation">Retrieval-Augmented Generation</h2> <p>The retrieval-augmented generation process in this project involves using a sentence transformer model from Hugging Face, specifically the <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">all-MiniLM-L6-v2</code></a>, to encode the comments. The encoded comments are then compared using cosine similarity to retrieve the most similar ones. The optimal threshold for cosine similarity was found to be around 0.5.</p> <p>For complex or lengthy input comments, where the likelihood of finding an exact match in the dataset is lower, a lower threshold can be employed to ensure some relevant outputs are retrieved. Conversely, for very short and straightforward sentences, a higher threshold can be beneficial to filter out only those comments that are strictly similar to the input, thus maintaining high precision. This dynamic adjustment of the threshold based on the input characteristics enhances the robustness and flexibility of the retrieval-augmented generation process.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nlp/output_career-480.webp 480w,/assets/img/nlp/output_career-800.webp 800w,/assets/img/nlp/output_career-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/nlp/output_career.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sentiment Analysis and Retrieval-Augmented Generation from a text input" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Sentiment Analysis and Retrieval-Augmented Generation from a text input </div> <h2 id="summary-generation-with-mistrals-llm">Summary Generation with Mistral’s LLM</h2> <p>For the summary generation component, we used a large language model (LLM) to generate summaries from the selected comments based on our similarity threshold and the chosen shot strategy. Prompt engineering played a crucial role in this process. We implemented various prompt strategies, including zero-shot, one-shot, two-shot, three-shot, and four-shot prompts, to determine which approach yielded the best results.</p> <p>The zero-shot prompt used was:</p> <p><code class="language-plaintext highlighter-rouge">Summarize shortly the comments provided above.</code> <code class="language-plaintext highlighter-rouge">Describe general emotions.</code></p> <p>The few-shot prompt was more structured:</p> <p>● <code class="language-plaintext highlighter-rouge">You are a summarizer bot.</code> ● <code class="language-plaintext highlighter-rouge">Your task is to given a group of comments you should return a general summary of the group of comments.</code> ● <code class="language-plaintext highlighter-rouge">You must not summarize each comment individually, you should summarize them as a whole.</code> ● <code class="language-plaintext highlighter-rouge">Describe general emotions.</code> ● <code class="language-plaintext highlighter-rouge">Do not provide additional explanations or notes, just the summary.</code> ● <code class="language-plaintext highlighter-rouge">Do not use more than 60 words.</code> ● <code class="language-plaintext highlighter-rouge">The group of comments is inside &lt;&lt;&lt;&gt;&gt;&gt;.</code> ● <code class="language-plaintext highlighter-rouge">Here are some examples: ...</code></p> <p>We experimented with two large language models: <a href="https://mistral.ai/news/announcing-mistral-7b/" rel="external nofollow noopener" target="_blank">Mistral 7B</a> and <a href="https://mistral.ai/news/mixtral-of-experts/" rel="external nofollow noopener" target="_blank">Mixtral 8x7B</a>. The Mixtral 8x7B model, which employs a sparse mixture of experts (MoEs) architecture, combines outputs from eight different experts efficiently, making both training and inference highly effective. We observed that Mixtral 8x7B outperformed Mistral 7B in the zero-shot prompt scenario, likely due to the greater flexibility and adaptability required in zero-shot tasks. However, with few-shot prompts, the additional examples provided sufficient orientation, leading to similar performance levels for both models.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nlp/zero-shot-480.webp 480w,/assets/img/nlp/zero-shot-800.webp 800w,/assets/img/nlp/zero-shot-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/nlp/zero-shot.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Zero-Shot Summarization" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Zero-Shot Summarization </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nlp/four-shot-480.webp 480w,/assets/img/nlp/four-shot-800.webp 800w,/assets/img/nlp/four-shot-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/nlp/four-shot" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Four-Shot Summarization" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Four-Shot Summarization </div> </div> </div> <p>The four-shot prompt strategy consistently yielded the best results. Our report concluded that structured and refined prompts significantly outperformed the original, unstructured prompts. Adding detailed instructions, a clear sequence of actions, and delimiters followed best practices for prompting, thereby achieving the desired output more effectively. The use of structured examples improved the models’ ability to capture nuanced emotional tones and specific contexts, highlighting the importance of precise prompt design in optimizing LLM performance for summarization tasks.</p> <h2 id="automatic-speech-recognition">Automatic Speech Recognition</h2> <p>The project also incorporates Automatic Speech Recognition (ASR) using <a href="https://openai.com/index/whisper/" rel="external nofollow noopener" target="_blank">OpenAI’s Whisper ASR model</a>. This allows the system to accept both audio and text inputs, converting audio to text with high accuracy before processing it for sentiment analysis, comment retrieval, and summarization. This functionality enhances the versatility and accessibility of the application, enabling users to interact with the system through multiple input modalities.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nlp/output_asr-480.webp 480w,/assets/img/nlp/output_asr-800.webp 800w,/assets/img/nlp/output_asr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/nlp/output_asr.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sentiment Analysis and Retrieval-Augmented Generation from a text input" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Sentiment Analysis and Retrieval-Augmented Generation from a text input </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 David Pérez Carrasco. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>